{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_corpus(directory, test_ratio=0.2):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "\n",
    "    num_test_files = int(len(file_list) * test_ratio)\n",
    "    test_files = random.sample(file_list, num_test_files)\n",
    "    train_files = [file for file in file_list if file not in test_files]\n",
    "    return train_files, test_files\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    words = []\n",
    "    for sentence in root.findall(\".//s\"):\n",
    "        words.append(\"<s>\")\n",
    "        for wtext in sentence.findall(\".//w\"):\n",
    "            if wtext.text is not None and wtext.text.strip().lower() != \"\":\n",
    "                words.append(wtext.text.strip().lower())\n",
    "        words.append(\"</s>\")\n",
    "    return words\n",
    "\n",
    "def split_list(lst, delimiter):\n",
    "    result = []\n",
    "    sublist = []\n",
    "    for item in lst:\n",
    "        if item == delimiter:\n",
    "            if sublist:\n",
    "                result.append(sublist)\n",
    "                sublist = []\n",
    "        else:\n",
    "            sublist.append(item)\n",
    "    if sublist:\n",
    "        result.append(sublist)\n",
    "    return result\n",
    "\n",
    "root_dir = os.path.join(\"British National Corpus, Baby edition\", \"Texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in training set: 146\n",
      "Number of files in test set: 36\n",
      "Number of word in training set: 3989656\n",
      "Number of word in test set: 678057\n",
      "Number of words in all corpus: 4667713\n",
      "Number of unique words in training set: 76562\n",
      "Number of unique words in test set: 33934\n",
      "Number of unique words in all corpus: 85768\n"
     ]
    }
   ],
   "source": [
    "train_files, test_files = split_corpus(root_dir)\n",
    "\n",
    "print(\"Number of files in training set:\", len(train_files))\n",
    "print(\"Number of files in test set:\", len(test_files))\n",
    "\n",
    "train_words = sum([parse_xml(xml_file) for xml_file in train_files], [])\n",
    "test_words = sum([parse_xml(xml_file) for xml_file in test_files], [])\n",
    "all_words = train_words + test_words\n",
    "\n",
    "print(\"Number of word in training set:\" , len(train_words))\n",
    "print(\"Number of word in test set:\", len(test_words))\n",
    "print(\"Number of words in all corpus:\", len(train_words) + len(test_words))\n",
    "\n",
    "print(\"Number of unique words in training set:\", len(set(train_words)))\n",
    "print(\"Number of unique words in test set:\", len(set(test_words)))\n",
    "print(\"Number of unique words in all corpus:\", len(set(train_words + test_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaLanguageModel:\n",
    "    def __init__(self, xml_files: list = None, words: list[str] = None):\n",
    "        self.xml_files = xml_files\n",
    "        if words is not None:\n",
    "            self.words = words\n",
    "        elif xml_files is not None:\n",
    "            self.words = self._parse_xml_files()\n",
    "        self.gram = {\n",
    "            1: {},\n",
    "            2: {},\n",
    "            3: {},\n",
    "        }\n",
    "\n",
    "    def _parse_xml_files(self):\n",
    "        words = sum([parse_xml(xml_file) for xml_file in self.xml_files], [])\n",
    "        return words\n",
    "\n",
    "    def _parse_xml(self, xml_file):\n",
    "        return parse_xml(xml_file)\n",
    "\n",
    "    def _count_ngrams(self, words: str, ngram: int):\n",
    "        grams = self._tokenize(words, ngram)\n",
    "        gram_counts: dict = {}\n",
    "        for gram in grams:\n",
    "            if gram in gram_counts:\n",
    "                gram_counts[gram] += 1\n",
    "            else:\n",
    "                gram_counts[gram] = 1\n",
    "        return gram_counts\n",
    "\n",
    "    def _tokenize(self, words: str, ngram: int):\n",
    "        ngrams = [tuple(words[i:i+ngram]) for i in range(len(words)-ngram+1)]\n",
    "        return ngrams\n",
    "\n",
    "    def _calculate_probability(self, ngram: int, word: str, context: tuple):\n",
    "        numerator = self.gram[ngram].get(context + (word,), 0)\n",
    "        if ngram - 1 >= 1:\n",
    "            denominator = self.gram[ngram - 1].get(context, 0)\n",
    "        else:\n",
    "            denominator = len(self.gram[ngram])\n",
    "        if numerator == 0:\n",
    "            return 0\n",
    "        return math.log(numerator / denominator)\n",
    "\n",
    "    def _calculate_sentence_probability(self, tokens: list, ngram: int):\n",
    "        n = len(tokens)\n",
    "        probability: float = 0.0\n",
    "\n",
    "        for i in range(0, n):\n",
    "            if ngram == 1:\n",
    "                probability += self._calculate_probability(1, tokens[i], tuple())\n",
    "            else:\n",
    "                if i < ngram - 1:\n",
    "                    _prob = self._calculate_probability(i+1, tokens[i], tuple(tokens[:i]))\n",
    "                    probability += _prob\n",
    "                else:\n",
    "                    _prob = self._calculate_probability(ngram, tokens[i], tuple(tokens[i-ngram+1:i]))\n",
    "                    probability += _prob\n",
    "        return probability\n",
    "\n",
    "    def _check_ngram(self, ngram: int):\n",
    "        if ngram in self.gram:\n",
    "            return True\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid ngram. Choose from 1 to {len(self.gram)}.\")\n",
    "\n",
    "    def train(self, ngram: int = 3):\n",
    "        for i in range(1, ngram+1):\n",
    "            self.gram[i] = self._count_ngrams(self.words, i)\n",
    "\n",
    "    def get_top_ngrams(self, ngram, top_n=10):\n",
    "        self._check_ngram(ngram)\n",
    "\n",
    "        ngram_counts: dict = self.gram[ngram]\n",
    "\n",
    "        return sorted(ngram_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    def get_ngam_probability(self, ngram: int):\n",
    "        total_count = sum(self.gram[ngram].values())\n",
    "        ngram_probabilities = {k: v / total_count for k, v in self.gram[ngram].items()}\n",
    "        return ngram_probabilities\n",
    "\n",
    "    def get_top_ngram_probability(self, ngram: int, top_n=10):\n",
    "        ngram_probabilities = self.get_ngam_probability(ngram)\n",
    "        return sorted(ngram_probabilities.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    def calculate_perplexity(self, words: list, ngram: int):\n",
    "        self._check_ngram(ngram)\n",
    "\n",
    "        log_sentence_probability = self._calculate_sentence_probability(words, ngram)\n",
    "        perplexity = math.exp(-log_sentence_probability / len(words))\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 unigrams: [(('<s>',), 258418), (('</s>',), 258418), (('the',), 164216), (('of',), 78712), (('and',), 72920), (('to',), 72602), (('a',), 67912), (('in',), 53041), (('it',), 48151), (('i',), 48014)]\n",
      "Top 10 bigrams: [(('</s>', '<s>'), 258417), (('of', 'the'), 18274), (('<s>', 'i'), 16951), (('<s>', 'the'), 15522), (('in', 'the'), 14247), (('<s>', 'yeah'), 9449), (('<s>', 'it'), 9295), (('it', \"'s\"), 8655), (('<s>', 'he'), 8521), (('yeah', '</s>'), 7476)]\n",
      "Top 10 trigrams: [(('</s>', '<s>', 'i'), 16951), (('</s>', '<s>', 'the'), 15522), (('</s>', '<s>', 'yeah'), 9449), (('</s>', '<s>', 'it'), 9295), (('</s>', '<s>', 'he'), 8521), (('yeah', '</s>', '<s>'), 7476), (('it', '</s>', '<s>'), 7289), (('</s>', '<s>', 'oh'), 7171), (('</s>', '<s>', 'you'), 6482), (('</s>', '<s>', 'no'), 6382)]\n",
      "Top 10 unigram probabilities: [(('<s>',), 0.07175365775167356), (('</s>',), 0.07175365775167356), (('the',), 0.04559705075245852), (('of',), 0.02185557472370241), (('and',), 0.02024733851067664), (('to',), 0.020159041011411756), (('a',), 0.018856791729800766), (('in',), 0.014727634146253422), (('it',), 0.013369851846236847), (('i',), 0.01333181172862902)]\n",
      "Top 10 bigram probabilities: [(('</s>', '<s>'), 0.07175340000999594), (('of', 'the'), 0.005074053300605865), (('<s>', 'i'), 0.00470670228185236), (('<s>', 'the'), 0.004309918755171514), (('in', 'the'), 0.0039558956645360495), (('<s>', 'yeah'), 0.0026236581830701993), (('<s>', 'it'), 0.002580897747024818), (('it', \"'s\"), 0.0024031920387842707), (('<s>', 'he'), 0.0023659849061214064), (('yeah', '</s>'), 0.0020758248043848885)]\n",
      "Top 10 trigram probabilities: [(('</s>', '<s>', 'i'), 0.004706703588740008), (('</s>', '<s>', 'the'), 0.004309919951886166), (('</s>', '<s>', 'yeah'), 0.0026236589115688947), (('</s>', '<s>', 'it'), 0.002580898463650426), (('</s>', '<s>', 'he'), 0.002365985563073188), (('yeah', '</s>', '<s>'), 0.0020758253807692936), (('it', '</s>', '<s>'), 0.002023901979725439), (('</s>', '<s>', 'oh'), 0.001991137480671028), (('</s>', '<s>', 'you'), 0.0017998261260228146), (('</s>', '<s>', 'no'), 0.0017720596014004324)]\n"
     ]
    }
   ],
   "source": [
    "vanilla_model = VanillaLanguageModel(words=train_words)\n",
    "vanilla_model.train()\n",
    "\n",
    "print(\"Top 10 unigrams:\", vanilla_model.get_top_ngrams(1))\n",
    "print(\"Top 10 bigrams:\", vanilla_model.get_top_ngrams(2))\n",
    "print(\"Top 10 trigrams:\", vanilla_model.get_top_ngrams(3))\n",
    "print(\"Top 10 unigram probabilities:\", vanilla_model.get_top_ngram_probability(1))\n",
    "print(\"Top 10 bigram probabilities:\", vanilla_model.get_top_ngram_probability(2))\n",
    "print(\"Top 10 trigram probabilities:\", vanilla_model.get_top_ngram_probability(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(VanillaLanguageModel):\n",
    "    def __init__(self, xml_files: list = None, words: list[str] = None):\n",
    "        super().__init__(xml_files, words)\n",
    "\n",
    "    def _calculate_probability(self, ngram: int, word: str, context: tuple):\n",
    "        numerator = self.gram[ngram].get(context + (word,), 0)\n",
    "        if ngram - 1 >= 1:\n",
    "            denominator = self.gram[ngram - 1].get(context, 0)\n",
    "        else:\n",
    "            denominator = len(self.gram[ngram])\n",
    "        return math.log((numerator + 1) / (denominator + len(self.gram[ngram])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams with Laplace Smoothing: [(('<s>',), 258418), (('</s>',), 258418), (('the',), 164216), (('of',), 78712), (('and',), 72920), (('to',), 72602), (('a',), 67912), (('in',), 53041), (('it',), 48151), (('i',), 48014)]\n",
      "Top 10 Bigrams with Laplace Smoothing: [(('</s>', '<s>'), 258417), (('of', 'the'), 18274), (('<s>', 'i'), 16951), (('<s>', 'the'), 15522), (('in', 'the'), 14247), (('<s>', 'yeah'), 9449), (('<s>', 'it'), 9295), (('it', \"'s\"), 8655), (('<s>', 'he'), 8521), (('yeah', '</s>'), 7476)]\n",
      "Top 10 Trigrams with Laplace Smoothing: [(('</s>', '<s>', 'i'), 16951), (('</s>', '<s>', 'the'), 15522), (('</s>', '<s>', 'yeah'), 9449), (('</s>', '<s>', 'it'), 9295), (('</s>', '<s>', 'he'), 8521), (('yeah', '</s>', '<s>'), 7476), (('it', '</s>', '<s>'), 7289), (('</s>', '<s>', 'oh'), 7171), (('</s>', '<s>', 'you'), 6482), (('</s>', '<s>', 'no'), 6382)]\n"
     ]
    }
   ],
   "source": [
    "laplace_model = LaplaceLanguageModel(words=train_words)\n",
    "laplace_model.train()\n",
    "\n",
    "print(\"Top 10 Unigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(1))\n",
    "print(\"Top 10 Bigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(2))\n",
    "print(\"Top 10 Trigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNKLanguageModel(VanillaLanguageModel):\n",
    "    def __init__(self, xml_files: list = None, words: list[str] = None):\n",
    "        super().__init__(xml_files, words)\n",
    "        self.unk_threshold = 2\n",
    "        self._replace_rare_words()\n",
    "\n",
    "    def _replace_rare_words(self):\n",
    "        word_counts = {}\n",
    "        for word in self.words:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "        for i, word in enumerate(self.words):\n",
    "            if word_counts[word] <= self.unk_threshold:\n",
    "                self.words[i] = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams after replacing rare words with <UNK>: [(('<s>',), 258418), (('</s>',), 258418), (('the',), 164216), (('of',), 78712), (('and',), 72920), (('to',), 72602), (('a',), 67912), (('in',), 53041), (('<UNK>',), 50801), (('it',), 48151)]\n",
      "Top 10 Bigrams after replacing rare words with <UNK>: [(('</s>', '<s>'), 258417), (('of', 'the'), 18274), (('<s>', 'i'), 16951), (('<s>', 'the'), 15522), (('in', 'the'), 14247), (('<s>', 'yeah'), 9449), (('<s>', 'it'), 9295), (('it', \"'s\"), 8655), (('<s>', 'he'), 8521), (('yeah', '</s>'), 7476)]\n",
      "Top 10 Trigrams after replacing rare words with <UNK>: [(('</s>', '<s>', 'i'), 16951), (('</s>', '<s>', 'the'), 15522), (('</s>', '<s>', 'yeah'), 9449), (('</s>', '<s>', 'it'), 9295), (('</s>', '<s>', 'he'), 8521), (('yeah', '</s>', '<s>'), 7476), (('it', '</s>', '<s>'), 7289), (('</s>', '<s>', 'oh'), 7171), (('<UNK>', '</s>', '<s>'), 6636), (('</s>', '<s>', 'you'), 6482)]\n",
      "Is there any trigram with empty string after replacing rare words with <UNK>: False\n"
     ]
    }
   ],
   "source": [
    "unk_model = UNKLanguageModel(train_files)\n",
    "unk_model.train()\n",
    "\n",
    "print(\"Top 10 Unigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(1))\n",
    "print(\"Top 10 Bigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(2))\n",
    "print(\"Top 10 Trigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams with Laplace Smoothing after replacing rare words with <UNK>: [(('<s>',), 258418), (('</s>',), 258418), (('the',), 164216), (('of',), 78712), (('and',), 72920), (('to',), 72602), (('a',), 67912), (('in',), 53041), (('<UNK>',), 50801), (('it',), 48151)]\n",
      "Top 10 Bigrams with Laplace Smoothing after replacing rare words with <UNK>: [(('</s>', '<s>'), 258417), (('of', 'the'), 18274), (('<s>', 'i'), 16951), (('<s>', 'the'), 15522), (('in', 'the'), 14247), (('<s>', 'yeah'), 9449), (('<s>', 'it'), 9295), (('it', \"'s\"), 8655), (('<s>', 'he'), 8521), (('yeah', '</s>'), 7476)]\n",
      "Top 10 Trigrams with Laplace Smoothing after replacing rare words with <UNK>: [(('</s>', '<s>', 'i'), 16951), (('</s>', '<s>', 'the'), 15522), (('</s>', '<s>', 'yeah'), 9449), (('</s>', '<s>', 'it'), 9295), (('</s>', '<s>', 'he'), 8521), (('yeah', '</s>', '<s>'), 7476), (('it', '</s>', '<s>'), 7289), (('</s>', '<s>', 'oh'), 7171), (('<UNK>', '</s>', '<s>'), 6636), (('</s>', '<s>', 'you'), 6482)]\n"
     ]
    }
   ],
   "source": [
    "laplace_unk_model = LaplaceLanguageModel(words=unk_model.words)\n",
    "laplace_unk_model.train()\n",
    "\n",
    "print(\"Top 10 Unigrams with Laplace Smoothing after replacing rare words with <UNK>:\", laplace_unk_model.get_top_ngrams(1))\n",
    "print(\"Top 10 Bigrams with Laplace Smoothing after replacing rare words with <UNK>:\", laplace_unk_model.get_top_ngrams(2))\n",
    "print(\"Top 10 Trigrams with Laplace Smoothing after replacing rare words with <UNK>:\", laplace_unk_model.get_top_ngrams(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation_probability(language_model: VanillaLanguageModel, sentence: list):\n",
    "    trigram_lambda = 0.6\n",
    "    bigram_lambda = 0.3\n",
    "    unigram_lambda = 0.1\n",
    "\n",
    "    trigram_prob = language_model.calculate_perplexity(sentence, 3)\n",
    "    bigram_prob = language_model.calculate_perplexity(sentence, 2)\n",
    "    unigram_prob = language_model.calculate_perplexity(sentence, 1)\n",
    "\n",
    "    total_prob = (\n",
    "        trigram_lambda * trigram_prob +\n",
    "        bigram_lambda * bigram_prob +\n",
    "        unigram_lambda * unigram_prob\n",
    "    )\n",
    "\n",
    "    return total_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            | Unigram | Bigram | Trigram | Linear Interpolation |\n",
      "|------------|---------|--------|---------|----------------------|\n",
      "| Vanilla    | 15.49   | 24.26  | 3.70  | 11.05 |\n",
      "| Laplace    | 38.78   | 18920.83  | 398664.74  | 244878.97 |\n",
      "| UNK        | 6.06   | 23.88  | 3.69  | 9.99 |\n"
     ]
    }
   ],
   "source": [
    "vanilla_unigram_perplexity = vanilla_model.calculate_perplexity(test_words, ngram=1)\n",
    "vanilla_bigram_perplexity = vanilla_model.calculate_perplexity(test_words, ngram=2)\n",
    "vanilla_trigram_perplexity = vanilla_model.calculate_perplexity(test_words, ngram=3)\n",
    "vanilla_linear_interpolation = linear_interpolation_probability(vanilla_model, test_words)\n",
    "\n",
    "laplace_unigram_perplexity = laplace_model.calculate_perplexity(test_words, ngram=1)\n",
    "laplace_bigram_perplexity = laplace_model.calculate_perplexity(test_words, ngram=2)\n",
    "laplace_trigram_perplexity = laplace_model.calculate_perplexity(test_words, ngram=3)\n",
    "laplace_linear_interpolation = linear_interpolation_probability(laplace_model, test_words)\n",
    "\n",
    "unk_unigram_perplexity = unk_model.calculate_perplexity(test_words, ngram=1)\n",
    "unk_bigram_perplexity = unk_model.calculate_perplexity(test_words, ngram=2)\n",
    "unk_trigram_perplexity = unk_model.calculate_perplexity(test_words, ngram=3)\n",
    "unk_linear_interpolation = linear_interpolation_probability(unk_model, test_words)\n",
    "\n",
    "print(\"|            | Unigram | Bigram | Trigram | Linear Interpolation |\")\n",
    "print(\"|------------|---------|--------|---------|----------------------|\")\n",
    "print(f\"| Vanilla    | {vanilla_unigram_perplexity:.2f}   | {vanilla_bigram_perplexity:.2f}  | {vanilla_trigram_perplexity:.2f}  | {vanilla_linear_interpolation:.2f} |\")\n",
    "print(f\"| Laplace    | {laplace_unigram_perplexity:.2f}   | {laplace_bigram_perplexity:.2f}  | {laplace_trigram_perplexity:.2f}  | {laplace_linear_interpolation:.2f} |\")\n",
    "print(f\"| UNK        | {unk_unigram_perplexity:.2f}   | {unk_bigram_perplexity:.2f}  | {unk_trigram_perplexity:.2f}  | {unk_linear_interpolation:.2f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_end_tokens(sentence: str):\n",
    "    return sentence.replace(\"<s>\", \"\\n\").replace(\"</s>\", \"\").strip().capitalize()\n",
    "\n",
    "def generate_sentence(language_model: VanillaLanguageModel, starting_phrase: str, ngram: int = 3):\n",
    "    sentence = starting_phrase.lower().split()\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        context = tuple(sentence[-(ngram - 1):])\n",
    "        next_word = generate_next_word(language_model, context, ngram)\n",
    "        print(\"next_word: \", next_word)\n",
    "        if next_word[0] == \"</s>\":\n",
    "            if i < 4 and next_word[1]:\n",
    "                sentence.append(next_word[1])\n",
    "            else:\n",
    "                sentence.append(next_word[0])\n",
    "                break\n",
    "        sentence.append(next_word[0])\n",
    "\n",
    "    return remove_start_end_tokens(' '.join(sentence))\n",
    "\n",
    "\n",
    "def generate_next_word(language_model: VanillaLanguageModel, context, ngram: int):\n",
    "    candidates = language_model.gram[ngram]\n",
    "\n",
    "    if ngram == 1:\n",
    "        candidates = {k: v for k, v in candidates.items() if k != ''}\n",
    "    else:\n",
    "        candidates = {k[-1]: v for k, v in candidates.items() if k[:-1] == context}\n",
    "\n",
    "    if not candidates:\n",
    "        return \"</s>\"\n",
    "\n",
    "    total_count = sum(candidates.values())\n",
    "\n",
    "    probabilities = {word: count / total_count for word, count in candidates.items()}\n",
    "    sorted_data = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_3_elements = sorted_data[:3]\n",
    "\n",
    "    top_3_text = [item[0] for item in top_3_elements]\n",
    "    return top_3_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid model selection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m unk_model\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model selection.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m starting_phrase \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter a starting phrase: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m generated_sentence \u001b[38;5;241m=\u001b[39m generate_sentence(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstarting_phrase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, ngram\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid model selection."
     ]
    }
   ],
   "source": [
    "selected_model = input(\"Select a language model (Vanilla, Laplace, UNK): \").lower()\n",
    "\n",
    "if selected_model == \"vanilla\":\n",
    "    model = vanilla_model\n",
    "elif selected_model == \"laplace\":\n",
    "    model = laplace_model\n",
    "elif selected_model == \"unk\":\n",
    "    model = unk_model\n",
    "else:\n",
    "    raise ValueError(\"Invalid model selection.\")\n",
    "\n",
    "starting_phrase = input(\"Enter a starting phrase: \")\n",
    "\n",
    "generated_sentence = generate_sentence(model, f\"<s> {starting_phrase}\", ngram=3)\n",
    "print(\"Generated sentence: \", generated_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
