{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Language Model - Part I\n",
    "\n",
    "## Downloading Pretrained Models\n",
    "\n",
    "Google drive Folders with all 3 Pretrained file:\n",
    "[https://drive.google.com/drive/folders/17r9wsbGnEg_Sr5S_LlSBstKekHCFXjR6?usp=drive_link](https://drive.google.com/drive/folders/17r9wsbGnEg_Sr5S_LlSBstKekHCFXjR6?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Read and parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_corpus(directory, test_ratio=0.2):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xml\"):\n",
    "                file_list.append(os.path.join(root, file))\n",
    "\n",
    "    num_test_files = int(len(file_list) * test_ratio)\n",
    "    test_files = random.sample(file_list, num_test_files)\n",
    "    train_files = [file for file in file_list if file not in test_files]\n",
    "    return train_files, test_files\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    sentences = []\n",
    "    for sentence in root.findall(\".//s\"):\n",
    "        words = []\n",
    "        words.append(\"<s>\")\n",
    "        for wtext in sentence.findall(\".//w\"):\n",
    "            if wtext.text is not None and wtext.text.strip().lower() != \"\":\n",
    "                words.append(wtext.text.strip().lower())\n",
    "        words.append(\"</s>\")\n",
    "        sentences.append(words)\n",
    "    return sentences\n",
    "\n",
    "def split_list(lst, delimiter):\n",
    "    result = []\n",
    "    sublist = []\n",
    "    for item in lst:\n",
    "        if item == delimiter:\n",
    "            if sublist:\n",
    "                result.append(sublist)\n",
    "                sublist = []\n",
    "        else:\n",
    "            sublist.append(item)\n",
    "    if sublist:\n",
    "        result.append(sublist)\n",
    "    return result\n",
    "\n",
    "root_dir = os.path.join(\"British National Corpus, Baby edition\", \"Texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How large is the corpus that you are working with? What splits did you use?**\n",
    "\n",
    "Data is randomly distributed, with 80% of files for training and 20% for testing. You'll find more details on the data below.\n",
    "\n",
    "**How much space did your data structures require once all models were learnt?**\n",
    "\n",
    "My Vanilla model take 163 218 Ko, my Laplace model take 163 218 Ko and my Unk model take 154 243 Ko, for a total of 490 679 Ko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in training set: 146\n",
      "Number of files in test set: 36\n",
      "Number of word in training set: 3579912\n",
      "Number of word in test set: 1087801\n",
      "Number of words in all corpus: 4667713\n",
      "Number of unique words in training set: 72399\n",
      "Number of unique words in test set: 39728\n",
      "Number of unique words in all corpus: 85768\n"
     ]
    }
   ],
   "source": [
    "train_files, test_files = split_corpus(root_dir)\n",
    "\n",
    "print(\"Number of files in training set:\", len(train_files))\n",
    "print(\"Number of files in test set:\", len(test_files))\n",
    "\n",
    "train_sentences = sum([parse_xml(xml_file) for xml_file in train_files], [])\n",
    "test_sentences = sum([parse_xml(xml_file) for xml_file in test_files], [])\n",
    "train_words = [word for sentence in train_sentences for word in sentence]\n",
    "test_words = [word for sentence in test_sentences for word in sentence]\n",
    "\n",
    "print(\"Number of word in training set:\" , len(train_words))\n",
    "print(\"Number of word in test set:\", len(test_words))\n",
    "print(\"Number of words in all corpus:\", len(train_words) + len(test_words))\n",
    "\n",
    "print(\"Number of unique words in training set:\", len(set(train_words)))\n",
    "print(\"Number of unique words in test set:\", len(set(test_words)))\n",
    "print(\"Number of unique words in all corpus:\", len(set(train_words + test_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Language Model\n",
    "\n",
    "The Vanilla Language model is your regular language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaLanguageModel:\n",
    "    def __init__(self, sentences: list[list[str]] = None, words: list[str] = None, model_data: dict = None):\n",
    "        self.gram: dict[int, dict[tuple, int]] = {\n",
    "            1: {},\n",
    "            2: {},\n",
    "            3: {},\n",
    "        }\n",
    "        self.words: list[str] = None\n",
    "        if sentences is not None:\n",
    "            self.words: list[str] = [word for sentence in sentences for word in sentence]\n",
    "        elif words is not None:\n",
    "            self.words: list[str] = words\n",
    "        elif model_data is not None:\n",
    "            self.load_model(model_data)\n",
    "        else:\n",
    "            raise ValueError(\"Either sentences or words or gram must be provided.\")\n",
    "        if self.words:\n",
    "            self.words_count: int = len(self.words)\n",
    "            self.words_vocabulary_count: int = len(set(self.words))\n",
    "\n",
    "    def _count_ngrams(self, words: str, ngram: int):\n",
    "        grams = self._tokenize(words, ngram)\n",
    "        gram_counts: dict = {}\n",
    "        for gram in grams:\n",
    "            if gram in gram_counts:\n",
    "                gram_counts[gram] += 1\n",
    "            else:\n",
    "                gram_counts[gram] = 1\n",
    "        return gram_counts\n",
    "\n",
    "    def _tokenize(self, words: str, ngram: int):\n",
    "        ngrams = [tuple(words[i:i+ngram]) for i in range(len(words)-ngram+1)]\n",
    "        return ngrams\n",
    "\n",
    "    def _calculate_probability(self, ngram: int, word: str, context: tuple, log_format: bool = False):\n",
    "        numerator = self.gram[ngram].get(context + (word,), 0)\n",
    "        if ngram - 1 >= 1:\n",
    "            denominator = self.gram[ngram - 1].get(context, 0)\n",
    "        else:\n",
    "            denominator = self.words_count\n",
    "        if numerator == 0:\n",
    "            return 0\n",
    "        if log_format:\n",
    "            return math.log(numerator / denominator)\n",
    "        else:\n",
    "            return numerator / denominator\n",
    "\n",
    "    def calculate_sentence_probability_log(self, tokens: list, ngram: int):\n",
    "        n = len(tokens)\n",
    "        probability: float = 0.0\n",
    "\n",
    "        for i in range(ngram-1, n):\n",
    "            if ngram == 1:\n",
    "                probability += self._calculate_probability(1, tokens[i], tuple(), True)\n",
    "            else:\n",
    "                if i < ngram - 1:\n",
    "                    _prob = self._calculate_probability(i+1, tokens[i], tuple(tokens[:i]), True)\n",
    "                    probability += _prob\n",
    "                else:\n",
    "                    _prob = self._calculate_probability(ngram, tokens[i], tuple(tokens[i-ngram+1:i]), True)\n",
    "                    probability += _prob\n",
    "        return probability\n",
    "\n",
    "    def calculate_sentence_probability(self, tokens: list, ngram: int):\n",
    "        n = len(tokens)\n",
    "        probability: float = 1.0\n",
    "\n",
    "        for i in range(ngram-1, n):\n",
    "            if ngram == 1:\n",
    "                probability *= self._calculate_probability(1, tokens[i], tuple())\n",
    "            else:\n",
    "                if i < ngram - 1:\n",
    "                    _prob = self._calculate_probability(i+1, tokens[i], tuple(tokens[:i]))\n",
    "                    probability *= _prob\n",
    "                else:\n",
    "                    _prob = self._calculate_probability(ngram, tokens[i], tuple(tokens[i-ngram+1:i]))\n",
    "                    probability *= _prob\n",
    "        return probability\n",
    "\n",
    "    def _check_ngram(self, ngram: int):\n",
    "        if ngram in self.gram:\n",
    "            return True\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid ngram. Choose from 1 to {len(self.gram)}.\")\n",
    "\n",
    "    def train(self, ngram: int = 3):\n",
    "        for i in range(1, ngram+1):\n",
    "            self.gram[i] = self._count_ngrams(self.words, i)\n",
    "\n",
    "    def get_top_ngrams(self, ngram, top_n=10):\n",
    "        self._check_ngram(ngram)\n",
    "\n",
    "        ngram_counts: dict = self.gram[ngram]\n",
    "\n",
    "        return sorted(ngram_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    def get_ngam_probability(self, ngram: int):\n",
    "        ngram_probabilities = {k: self._calculate_probability(ngram, k[-1], k[:-1]) for k in self.gram[ngram].keys()}\n",
    "        return ngram_probabilities\n",
    "\n",
    "    def get_top_ngram_probability(self, ngram: int, top_n=10):\n",
    "        ngram_probabilities = self.get_ngam_probability(ngram)\n",
    "        return sorted(ngram_probabilities.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    def calculate_sentence_perplexity(self, words: list, ngram: int):\n",
    "        self._check_ngram(ngram)\n",
    "\n",
    "        log_sentence_probability = self.calculate_sentence_probability_log(words, ngram)\n",
    "        perplexity = math.exp(-log_sentence_probability / len(words))\n",
    "        return perplexity\n",
    "\n",
    "    def calculate_perplexity(self, sentences: list, ngram: int) -> float:\n",
    "        perplexities = []\n",
    "        for sentence in sentences:\n",
    "            perplexity = self.calculate_sentence_perplexity(sentence, ngram)\n",
    "            perplexities.append(perplexity)\n",
    "        average_perplexity = sum(perplexities) / len(perplexities)\n",
    "        return average_perplexity\n",
    "\n",
    "    def predict_next_word(self, context: tuple, ngram: int = 2):\n",
    "        next_word_probs = {}\n",
    "        context = tuple(context[-ngram+1:])\n",
    "        for ngram_tuple, count in self.gram[ngram].items():\n",
    "            if ngram_tuple[:-1] == context:\n",
    "                next_word = ngram_tuple[-1]\n",
    "                next_word_prob = self._calculate_probability(ngram, next_word, context)\n",
    "                next_word_probs[next_word] = next_word_prob\n",
    "\n",
    "        # print(sorted(next_word_probs.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "        if not next_word_probs:\n",
    "            raise ValueError(\"No words found for the given context.\")\n",
    "\n",
    "        predicted_word = max(next_word_probs, key=next_word_probs.get)\n",
    "        return predicted_word\n",
    "\n",
    "    def gram_to_json(self):\n",
    "        converted_dict = {}\n",
    "        for key, inner_dict in self.gram.items():\n",
    "            converted_inner_list = []\n",
    "            for inner_key, value in inner_dict.items():\n",
    "                converted_inner_list.append({\"key\": inner_key, \"value\": value})\n",
    "            converted_dict[key] = converted_inner_list\n",
    "        return json.dumps(converted_dict)\n",
    "\n",
    "    def json_to_gram(self, json_str):\n",
    "        loaded_dict: json = json.loads(json_str)\n",
    "        reconstructed_dict: dict = {}\n",
    "        for key, inner_list in loaded_dict.items():\n",
    "            reconstructed_inner_dict = {}\n",
    "            for item in inner_list:\n",
    "                inner_key = item[\"key\"]\n",
    "                value = item[\"value\"]\n",
    "                reconstructed_inner_dict[tuple(inner_key)] = int(value)\n",
    "            reconstructed_dict[int(key)] = reconstructed_inner_dict\n",
    "\n",
    "        return reconstructed_dict\n",
    "\n",
    "    def save_model(self, filename: str):\n",
    "        model_data = {\n",
    "            'gram': self.gram_to_json(),\n",
    "            'words_count': self.words_count,\n",
    "            'words_vocabulary_count': self.words_vocabulary_count,\n",
    "        }\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(json.dumps(model_data))\n",
    "\n",
    "    def load_model(self, model_data):\n",
    "        if isinstance(model_data, str):\n",
    "            with open(model_data, 'r') as f:\n",
    "                model_data = json.loads(f.read())\n",
    "        self.gram = self.json_to_gram(model_data['gram'])\n",
    "        self.words_count = model_data['words_count']\n",
    "        self.words_vocabulary_count = model_data['words_vocabulary_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much time does it take to build the language models?**\n",
    "\n",
    "It takes around 25.5 seconds to build the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 unigrams: [(('<s>',), 252371), (('</s>',), 252371), (('the',), 162608), (('of',), 75782), (('to',), 74517), (('and',), 72593), (('a',), 67803), (('in',), 51703), (('it',), 47233), (('i',), 46289)]\n",
      "Top 10 unigram probabilities: [(('<s>',), 0.07049642561046193), (('</s>',), 0.07049642561046193), (('the',), 0.04542234557720972), (('of',), 0.021168676771942996), (('to',), 0.02081531613067584), (('and',), 0.020277872752179384), (('a',), 0.018939851035444447), (('in',), 0.014442533782953324), (('it',), 0.01319389973831759), (('i',), 0.012930206105624942)]\n",
      "------------------------------\n",
      "Top 10 bigrams: [(('</s>', '<s>'), 252370), (('of', 'the'), 17603), (('<s>', 'i'), 16873), (('<s>', 'the'), 15243), (('in', 'the'), 14013), (('<s>', 'it'), 9347), (('<s>', 'he'), 9066), (('<s>', 'yeah'), 8584), (('it', \"'s\"), 8449), (('to', 'the'), 7356)]\n",
      "Top 10 bigram probabilities: [(('maya', 'deren'), 1.0), (('deren', 'says'), 1.0), (('underscores', 'a'), 1.0), (('incongruities', 'into'), 1.0), (('depiction', 'of'), 1.0), (('iconographic', 'programmes'), 1.0), (('annihilate', 'the'), 1.0), (('peruvian', 'art'), 1.0), (('enrique', 'tord'), 1.0), (('visitas', 'or'), 1.0)]\n",
      "------------------------------\n",
      "Top 10 trigrams: [(('</s>', '<s>', 'i'), 16873), (('</s>', '<s>', 'the'), 15243), (('</s>', '<s>', 'it'), 9347), (('</s>', '<s>', 'he'), 9066), (('</s>', '<s>', 'yeah'), 8584), (('yeah', '</s>', '<s>'), 7056), (('</s>', '<s>', 'oh'), 6731), (('it', '</s>', '<s>'), 6642), (('</s>', '<s>', 'and'), 6583), (('</s>', '<s>', 'you'), 6290)]\n",
      "Top 10 trigram probabilities: [(('image', '</s>', '<s>'), 1.0), (('guy', 'brett', '</s>'), 1.0), (('brett', '</s>', '<s>'), 1.0), (('images', 'matter', 'to'), 1.0), (('involuntary', 'as', 'the'), 1.0), (('response', 'itself', '</s>'), 1.0), (('itself', '</s>', '<s>'), 1.0), (('answer', 'should', 'have'), 1.0), (('some', 'objective', 'quality'), 1.0), (('objective', 'quality', 'about'), 1.0)]\n"
     ]
    }
   ],
   "source": [
    "vanilla_model = VanillaLanguageModel(train_sentences)\n",
    "vanilla_model.train()\n",
    "# vanilla_model.save_model(\"vanilla_model.json\")\n",
    "\n",
    "print(\"Top 10 unigrams:\", vanilla_model.get_top_ngrams(1))\n",
    "print(\"Top 10 unigram probabilities:\", vanilla_model.get_top_ngram_probability(1))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 bigrams:\", vanilla_model.get_top_ngrams(2))\n",
    "print(\"Top 10 bigram probabilities:\", vanilla_model.get_top_ngram_probability(2))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 trigrams:\", vanilla_model.get_top_ngrams(3))\n",
    "print(\"Top 10 trigram probabilities:\", vanilla_model.get_top_ngram_probability(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Language Model\n",
    "\n",
    "The Laplace Language model will take the Vanilla as its basis, but you will now include\n",
    "Laplace smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(VanillaLanguageModel):\n",
    "    def __init__(self, sentences: list[list[str]] = None, words: list[str] = None, model_data: dict = None):\n",
    "        super().__init__(sentences, words, model_data)\n",
    "\n",
    "    def _calculate_probability(self, ngram: int, word: str, context: tuple, log_format: bool = False):\n",
    "        numerator = self.gram[ngram].get(context + (word,), 0) + 1\n",
    "        if ngram - 1 >= 1:\n",
    "            denominator = self.gram[ngram - 1].get(context, 0) + self.words_vocabulary_count\n",
    "        else:\n",
    "            denominator = self.words_count + self.words_vocabulary_count\n",
    "        probability = numerator / denominator\n",
    "        return math.log(probability) if log_format else probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much time does it take to build the language models?**\n",
    "\n",
    "It takes around 13.5 seconds to build the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams with Laplace Smoothing: [(('<s>',), 252371), (('</s>',), 252371), (('the',), 162608), (('of',), 75782), (('to',), 74517), (('and',), 72593), (('a',), 67803), (('in',), 51703), (('it',), 47233), (('i',), 46289)]\n",
      "Top 10 unigram with Laplace Smoothing probabilities: [(('<s>',), 0.06909926345264683), (('</s>',), 0.06909926345264683), (('the',), 0.04452222168375037), (('of',), 0.02074932830199838), (('to',), 0.02040297225510095), (('and',), 0.019876182504720983), (('a',), 0.018564684113702257), (('in',), 0.0141565162440986), (('it',), 0.012932633611978826), (('i',), 0.01267416712322691)]\n",
      "------------------------------\n",
      "Top 10 Bigrams with Laplace Smoothing: [(('</s>', '<s>'), 252370), (('of', 'the'), 17603), (('<s>', 'i'), 16873), (('<s>', 'the'), 15243), (('in', 'the'), 14013), (('<s>', 'it'), 9347), (('<s>', 'he'), 9066), (('<s>', 'yeah'), 8584), (('it', \"'s\"), 8449), (('to', 'the'), 7356)]\n",
      "Top 10 bigram with Laplace Smoothing probabilities: [(('</s>', '<s>'), 0.7770760846137267), (('of', 'the'), 0.11880065595454208), (('in', 'the'), 0.11292324056018437), (('yeah', '</s>'), 0.08502614520831828), (('do', \"n't\"), 0.07646505086706513), (('on', 'the'), 0.07089497274888996), (('it', \"'s\"), 0.07063327537782534), (('it', '</s>'), 0.05552862110472114), (('at', 'the'), 0.053345235539384625), (('<s>', 'i'), 0.0519567694060412)]\n",
      "------------------------------\n",
      "Top 10 Trigrams with Laplace Smoothing: [(('</s>', '<s>', 'i'), 16873), (('</s>', '<s>', 'the'), 15243), (('</s>', '<s>', 'it'), 9347), (('</s>', '<s>', 'he'), 9066), (('</s>', '<s>', 'yeah'), 8584), (('yeah', '</s>', '<s>'), 7056), (('</s>', '<s>', 'oh'), 6731), (('it', '</s>', '<s>'), 6642), (('</s>', '<s>', 'and'), 6583), (('</s>', '<s>', 'you'), 6290)]\n",
      "Top 10 trigram with Laplace Smoothing probabilities: [(('yeah', '</s>', '<s>'), 0.08881756969353723), (('it', '</s>', '<s>'), 0.08404498930934579), (('<s>', 'yeah', '</s>'), 0.07226207969573861), (('</s>', '<s>', 'i'), 0.05195692938673334), (('mm', '</s>', '<s>'), 0.04800852082210154), (('</s>', '<s>', 'the'), 0.046937977454744755), (('you', '</s>', '<s>'), 0.04399783444032167), (('<s>', 'mm', '</s>'), 0.04192142024849112), (('i', 'do', \"n't\"), 0.039835020029517186), (('<s>', 'it', \"'s\"), 0.038448364445966776)]\n"
     ]
    }
   ],
   "source": [
    "laplace_model = LaplaceLanguageModel(train_sentences)\n",
    "laplace_model.train()\n",
    "# laplace_model.save_model(\"laplace_model.json\")\n",
    "\n",
    "print(\"Top 10 Unigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(1))\n",
    "print(\"Top 10 unigram with Laplace Smoothing probabilities:\", laplace_model.get_top_ngram_probability(1))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 Bigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(2))\n",
    "print(\"Top 10 bigram with Laplace Smoothing probabilities:\", laplace_model.get_top_ngram_probability(2))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 Trigrams with Laplace Smoothing:\", laplace_model.get_top_ngrams(3))\n",
    "print(\"Top 10 trigram with Laplace Smoothing probabilities:\", laplace_model.get_top_ngram_probability(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNK Language Model\n",
    "\n",
    "The UNK Language model will take the Vanilla as its basis, but now you will set all the words\n",
    "that have a count of 2 or less as \\<UNK> tokens. And then recalculate accordingly. And recalculate\n",
    "Laplace smoothing on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNKLanguageModel(VanillaLanguageModel):\n",
    "    def __init__(self, sentences: list[list[str]] = None, words: list[str] = None, model_data: dict = None):\n",
    "        super().__init__(sentences, words, model_data)\n",
    "        self.unk_threshold = 2\n",
    "        if self.words:\n",
    "            self._replace_rare_words()\n",
    "\n",
    "    # Set all the words that have a count of 2 or less as <UNK> tokens.\n",
    "    def _replace_rare_words(self):\n",
    "        word_counts = {}\n",
    "        for word in self.words:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "        for i, word in enumerate(self.words):\n",
    "            if word_counts[word] <= self.unk_threshold:\n",
    "                self.words[i] = '<UNK>'\n",
    "\n",
    "    def calculate_sentence_probability_log(self, tokens: list, ngram: int):\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token not in self.gram[1] or self.gram[1][token] <= 2:\n",
    "                tokens[i] = '<UNK>'\n",
    "        return super().calculate_sentence_probability_log(tokens, ngram)\n",
    "\n",
    "    # Recalculate Laplace smoothing on this model\n",
    "    def _calculate_probability(self, ngram: int, word: str, context: tuple, log_format: bool = False):\n",
    "        numerator = self.gram[ngram].get(context + (word,), 0) + 1\n",
    "        if ngram - 1 >= 1:\n",
    "            denominator = self.gram[ngram - 1].get(context, 0) + self.words_vocabulary_count\n",
    "        else:\n",
    "            denominator = self.words_count + self.words_vocabulary_count\n",
    "        probability = numerator / denominator\n",
    "        return math.log(probability) if log_format else probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much time does it take to build the language models?**\n",
    "\n",
    "It takes around 14 seconds to build the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unigrams after replacing rare words with <UNK>: [(('<s>',), 252371), (('</s>',), 252371), (('the',), 162608), (('of',), 75782), (('to',), 74517), (('and',), 72593), (('a',), 67803), (('in',), 51703), (('<UNK>',), 49836), (('it',), 47233)]\n",
      "Top 10 unigram after replacing rare words with <UNK> probabilities: [(('<s>',), 0.06909926345264683), (('</s>',), 0.06909926345264683), (('the',), 0.04452222168375037), (('of',), 0.02074932830199838), (('to',), 0.02040297225510095), (('and',), 0.019876182504720983), (('a',), 0.018564684113702257), (('in',), 0.0141565162440986), (('<UNK>',), 0.01364533305077251), (('it',), 0.012932633611978826)]\n",
      "------------------------------\n",
      "Top 10 Bigrams after replacing rare words with <UNK>: [(('</s>', '<s>'), 252370), (('of', 'the'), 17603), (('<s>', 'i'), 16873), (('<s>', 'the'), 15243), (('in', 'the'), 14013), (('<s>', 'it'), 9347), (('<s>', 'he'), 9066), (('<s>', 'yeah'), 8584), (('it', \"'s\"), 8449), (('to', 'the'), 7356)]\n",
      "Top 10 bigram after replacing rare words with <UNK> probabilities: [(('</s>', '<s>'), 0.7770760846137267), (('of', 'the'), 0.11880065595454208), (('in', 'the'), 0.11292324056018437), (('yeah', '</s>'), 0.08502614520831828), (('do', \"n't\"), 0.07646505086706513), (('on', 'the'), 0.07089497274888996), (('it', \"'s\"), 0.07063327537782534), (('it', '</s>'), 0.05552862110472114), (('at', 'the'), 0.053345235539384625), (('<UNK>', '</s>'), 0.05201456211396081)]\n",
      "------------------------------\n",
      "Top 10 Trigrams after replacing rare words with <UNK>: [(('</s>', '<s>', 'i'), 16873), (('</s>', '<s>', 'the'), 15243), (('</s>', '<s>', 'it'), 9347), (('</s>', '<s>', 'he'), 9066), (('</s>', '<s>', 'yeah'), 8584), (('yeah', '</s>', '<s>'), 7056), (('</s>', '<s>', 'oh'), 6731), (('it', '</s>', '<s>'), 6642), (('</s>', '<s>', 'and'), 6583), (('<UNK>', '</s>', '<s>'), 6357)]\n",
      "Top 10 trigram after replacing rare words with <UNK> probabilities: [(('yeah', '</s>', '<s>'), 0.08881756969353723), (('it', '</s>', '<s>'), 0.08404498930934579), (('<UNK>', '</s>', '<s>'), 0.08073035705216111), (('<s>', 'yeah', '</s>'), 0.07226207969573861), (('</s>', '<s>', 'i'), 0.05195692938673334), (('mm', '</s>', '<s>'), 0.04800852082210154), (('</s>', '<s>', 'the'), 0.046937977454744755), (('you', '</s>', '<s>'), 0.04399783444032167), (('<s>', 'mm', '</s>'), 0.04192142024849112), (('i', 'do', \"n't\"), 0.039835020029517186)]\n"
     ]
    }
   ],
   "source": [
    "unk_model = UNKLanguageModel(train_sentences)\n",
    "unk_model.train()\n",
    "# unk_model.save_model(\"unk_model.json\")\n",
    "\n",
    "print(\"Top 10 Unigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(1))\n",
    "print(\"Top 10 unigram after replacing rare words with <UNK> probabilities:\", unk_model.get_top_ngram_probability(1))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 Bigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(2))\n",
    "print(\"Top 10 bigram after replacing rare words with <UNK> probabilities:\", unk_model.get_top_ngram_probability(2))\n",
    "print(\"---\"*10)\n",
    "print(\"Top 10 Trigrams after replacing rare words with <UNK>:\", unk_model.get_top_ngrams(3))\n",
    "print(\"Top 10 trigram after replacing rare words with <UNK> probabilities:\", unk_model.get_top_ngram_probability(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "This function takes one of the above 3 flavours of language models and calculate the probability of a sentence using the following lambdas:\n",
    "- trigram = 0.6\n",
    "- bigram = 0.3\n",
    "- unigram = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(language_model: VanillaLanguageModel, sentences: list, get_perplexity: bool = False):\n",
    "    trigram_lambda = 0.6\n",
    "    bigram_lambda = 0.3\n",
    "    unigram_lambda = 0.1\n",
    "\n",
    "    prob = []\n",
    "    for sentence in sentences:\n",
    "        trigram_log_prob = language_model.calculate_sentence_probability_log(sentence, 3)\n",
    "        bigram_log_prob = language_model.calculate_sentence_probability_log(sentence, 2)\n",
    "        unigram_log_prob = language_model.calculate_sentence_probability_log(sentence, 1)\n",
    "\n",
    "        max_log_prob = max(trigram_log_prob, bigram_log_prob, unigram_log_prob)\n",
    "        log_total_prob = math.log(\n",
    "            math.exp(trigram_log_prob - max_log_prob) * trigram_lambda +\n",
    "            math.exp(bigram_log_prob - max_log_prob) * bigram_lambda +\n",
    "            math.exp(unigram_log_prob - max_log_prob) * unigram_lambda\n",
    "        ) + max_log_prob\n",
    "\n",
    "        if get_perplexity:\n",
    "            total_prob = math.exp(-log_total_prob / len(sentence))\n",
    "        else:\n",
    "            total_prob = math.exp(log_total_prob)\n",
    "        prob.append(total_prob)\n",
    "\n",
    "    log_total_prob = sum(prob) / len(prob)\n",
    "\n",
    "    return log_total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla model linear interpolation:  3.854574124399315e-05\n",
      "Unk model linear interpolation:  1.0655177220213108e-05\n",
      "Laplace model linear interpolation:  3.13519477877221e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Vanilla model linear interpolation: \", linear_interpolation(vanilla_model, [[\"<s>\", \"i\", \"know\", \"him\"]]))\n",
    "print(\"Unk model linear interpolation: \", linear_interpolation(unk_model, [[\"<s>\", \"i\", \"know\", \"him\"]]))\n",
    "print(\"Laplace model linear interpolation: \", linear_interpolation(laplace_model, [[\"<s>\", \"i\", \"know\", \"him\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Evaluation\n",
    "\n",
    "Take the test corpus, iterate through the sentences and calculate the probabilities for each\n",
    "sentence with every model. You will then use this to calculate the Perplexity.\n",
    "\n",
    "For the Perplexity calculation, I don't know why my laplace Perplexity is so big because in all my other evaluation calculations the model looks good but not for the Perplexity. I've tried a lot of tests and changes with no better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            | Unigram | Bigram | Trigram | Linear Interpolation |\n",
      "|------------|---------|--------|---------|----------------------|\n",
      "| Vanilla    | 641.15   | 29.60  | 3.29  | 3.51 |\n",
      "| Laplace    | 1104.03   | 2589.35  | 6509.62  | 1079.62 |\n",
      "| UNK        | 73.29   | 30.17  | 91.20  | 32.08 |\n"
     ]
    }
   ],
   "source": [
    "vanilla_unigram_perplexity = vanilla_model.calculate_perplexity(test_sentences, ngram=1)\n",
    "vanilla_bigram_perplexity = vanilla_model.calculate_perplexity(test_sentences, ngram=2)\n",
    "vanilla_trigram_perplexity = vanilla_model.calculate_perplexity(test_sentences, ngram=3)\n",
    "vanilla_linear_interpolation = linear_interpolation(vanilla_model, test_sentences, get_perplexity=True)\n",
    "\n",
    "laplace_unigram_perplexity = laplace_model.calculate_perplexity(test_sentences, ngram=1)\n",
    "laplace_bigram_perplexity = laplace_model.calculate_perplexity(test_sentences, ngram=2)\n",
    "laplace_trigram_perplexity = laplace_model.calculate_perplexity(test_sentences, ngram=3)\n",
    "laplace_linear_interpolation = linear_interpolation(laplace_model, test_sentences, get_perplexity=True)\n",
    "\n",
    "unk_unigram_perplexity = unk_model.calculate_perplexity(test_sentences, ngram=1)\n",
    "unk_bigram_perplexity = unk_model.calculate_perplexity(test_sentences, ngram=2)\n",
    "unk_trigram_perplexity = unk_model.calculate_perplexity(test_sentences, ngram=3)\n",
    "unk_linear_interpolation = linear_interpolation(unk_model, test_sentences, get_perplexity=True)\n",
    "\n",
    "print(\"|            | Unigram | Bigram | Trigram | Linear Interpolation |\")\n",
    "print(\"|------------|---------|--------|---------|----------------------|\")\n",
    "print(f\"| Vanilla    | {vanilla_unigram_perplexity:.2f}   | {vanilla_bigram_perplexity:.2f}  | {vanilla_trigram_perplexity:.2f}  | {vanilla_linear_interpolation:.2f} |\")\n",
    "print(f\"| Laplace    | {laplace_unigram_perplexity:.2f}   | {laplace_bigram_perplexity:.2f}  | {laplace_trigram_perplexity:.2f}  | {laplace_linear_interpolation:.2f} |\")\n",
    "print(f\"| UNK        | {unk_unigram_perplexity:.2f}   | {unk_bigram_perplexity:.2f}  | {unk_trigram_perplexity:.2f}  | {unk_linear_interpolation:.2f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_start_end_tokens(sentence: str):\n",
    "    return sentence.replace(\"<s>\", \"\\n\").replace(\"</s>\", \"\").strip().capitalize()\n",
    "\n",
    "def generate_sentence(language_model: VanillaLanguageModel, starting_sentence: str, ngram: int = 3):\n",
    "    sentence = starting_sentence.split()\n",
    "    old_taboo_words: list = [\"\", \"\", \"\"]\n",
    "    taboo_words: list = [\"\", \"\", \"\"]\n",
    "    taboo_lenght = len(taboo_words)\n",
    "    i = 0\n",
    "    while sentence[-1] != '</s>':\n",
    "        next_word = language_model.predict_next_word(tuple(sentence[-(ngram):]), ngram)\n",
    "        sentence.append(next_word)\n",
    "        taboo_words[i] = next_word\n",
    "        if old_taboo_words == taboo_words:\n",
    "            for j in range(1, taboo_lenght+1):\n",
    "                sentence.pop()\n",
    "            next_word = \"</s>\"\n",
    "            sentence.append(next_word)\n",
    "\n",
    "        if i == taboo_lenght - 1:\n",
    "            i = 0\n",
    "            old_taboo_words = taboo_words\n",
    "            taboo_words = [\"\", \"\", \"\"]\n",
    "        else:\n",
    "            i += 1\n",
    "    return remove_start_end_tokens(' '.join(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla_model = VanillaLanguageModel(model_data=\"vanilla_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplace_model = LaplaceLanguageModel(model_data=\"laplace_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNK Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unk_model = UNKLanguageModel(model_data=\"unk_model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Evaluation\n",
    "\n",
    "This function that allows the user to select one of the Language Models (Vanilla, Laplace, UNK) and input a phrase. The function will use this phrase to Generate the rest of the sentence until it encounters the end of sentence token (i.e. the LM says stop!)\n",
    "\n",
    "**Take a test input and generate a sentence using the different models.**\n",
    "\n",
    "I send to the input \"I love you like my\" and the output is:\n",
    "\n",
    "```\n",
    "[('</s>', 0.1), ('mum', 0.06666666666666667), ('other', 0.03333333333333333), ('leg', 0.03333333333333333), ('browny', 0.03333333333333333)]\n",
    "Vanilla model generated sentence:  I love you like my\n",
    "------------------------------\n",
    "[('</s>', 5.570797877526009e-05), ('mum', 4.1780984081445065e-05), ('other', 2.7853989387630044e-05), ('leg', 2.7853989387630044e-05), ('browny', 2.7853989387630044e-05)]\n",
    "Laplace model generated sentence:  I love you like my\n",
    "------------------------------\n",
    "[('</s>', 5.570797877526009e-05), ('mum', 4.1780984081445065e-05), ('<UNK>', 4.1780984081445065e-05), ('other', 2.7853989387630044e-05), ('leg', 2.7853989387630044e-05)]\n",
    "UNK model generated sentence:  I love you like my\n",
    "```\n",
    "\n",
    "I don't know why the highest probability is the token \"\\</s>\" after \"my\", but if we look at the words the probability follows, we can see some good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla model generated sentence:  I love you like to go to the other side of the world\n",
      "------------------------------\n",
      "Laplace model generated sentence:  I love you like to go to the other side of the world\n",
      "------------------------------\n",
      "Remove last 1 words\n",
      "Remove last 2 words\n",
      "Remove last 3 words\n",
      "UNK model generated sentence:  I love you like to go to the <unk> of\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "selected_model = input(\"Select a language model (Vanilla, Laplace, UNK or All): \").strip().lower()\n",
    "\n",
    "model: VanillaLanguageModel\n",
    "if selected_model == \"vanilla\":\n",
    "    model = vanilla_model\n",
    "elif selected_model == \"laplace\":\n",
    "    model = laplace_model\n",
    "elif selected_model == \"unk\":\n",
    "    model = unk_model\n",
    "elif selected_model == \"all\":\n",
    "    model = None\n",
    "else:\n",
    "    raise ValueError(\"Invalid model selection.\")\n",
    "\n",
    "starting_phrase = input(\"Enter a starting phrase: \")\n",
    "if model is None:\n",
    "    for key, value in {\n",
    "        \"Vanilla\": vanilla_model,\n",
    "        \"Laplace\": laplace_model,\n",
    "        \"UNK\": unk_model\n",
    "        }.items():\n",
    "        generated_sentence = generate_sentence(value, f\"<s> {starting_phrase}\", ngram=3)\n",
    "        print(f\"{key} model generated sentence: \", generated_sentence)\n",
    "        print(\"---\"*10)\n",
    "else:\n",
    "    generated_sentence = generate_sentence(model, f\"<s> {starting_phrase}\", ngram=3)\n",
    "    print(\"Generated sentence: \", generated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a test sentence and output its probability using all the different models.**\n",
    "\n",
    "I've run a few tests, which you can see below, and the results are good for all models. We can see that if the vanilla model doesn't know a word combination, the probability is 0. But for the laplace and UNK models, the probability isn't 0 because of smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla model probability for the sentence '['<s>', 'Tell', 'me', 'who', '</s>']':  0.0\n",
      "Laplace model probability for the sentence '['<s>', 'Tell', 'me', 'who', '</s>']':  1.1869652902621226e-17\n",
      "UNK model probability for the sentence '['<s>', 'Tell', 'me', 'who', '</s>']':  1.1869652902621226e-17\n",
      "Vanilla model probability for the sentence '['<s>', 'i', 'love', 'you', '</s>']':  0.0004005496696658084\n",
      "Laplace model probability for the sentence '['<s>', 'i', 'love', 'you', '</s>']':  1.0414990877009567e-10\n",
      "UNK model probability for the sentence '['<s>', 'i', 'love', 'you', '</s>']':  1.0414990877009567e-10\n",
      "Vanilla model probability for the sentence '['<s>', 'i', 'love', 'you', 'like', '</s>']':  2.560331695307014e-06\n",
      "Laplace model probability for the sentence '['<s>', 'i', 'love', 'you', 'like', '</s>']':  5.728896644348556e-15\n",
      "UNK model probability for the sentence '['<s>', 'i', 'love', 'you', 'like', '</s>']':  5.728896644348556e-15\n"
     ]
    }
   ],
   "source": [
    "def sen_probability(sentence: list, ngram: int = 3):\n",
    "    key: str\n",
    "    value: VanillaLanguageModel\n",
    "    for key, value in {\n",
    "        \"Vanilla\": vanilla_model,\n",
    "        \"Laplace\": laplace_model,\n",
    "        \"UNK\": unk_model\n",
    "    }.items():\n",
    "        probability = value.calculate_sentence_probability(sentence, ngram)\n",
    "        print(f\"{key} model probability for the sentence '{sentence}': \", probability)\n",
    "sentence = [\"<s>\"] + \"Tell me who\".split() + [\"</s>\"]\n",
    "sen_probability(sentence, 2)\n",
    "sen_probability([\"<s>\", \"i\", \"love\", \"you\", \"</s>\"])\n",
    "sen_probability([\"<s>\", \"i\", \"love\", \"you\", \"like\", \"</s>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "##### The testing part should detail how you tested the different components throughout your project development, what results were obtained and what fixes, if any, were required.\n",
    "\n",
    "One of the big problems I encountered was that calculating the probabilities of a long sentence in the test data set generated a \"math error\". So I tried to solve this problem, first by looking through the course slides to see if there was anything I was missing, and after a little while I found something about the log, so I searched the Internet for more information, and after a while I came across this article [https://web.stanford.edu/~jurafsky/slp3/3.pdf](https://web.stanford.edu/~jurafsky/slp3/3.pdf), I read it and tried to understand it, after a while I did a lot of tests and changed my way of calculating the probability of a sentence. I tried using the logarithm of probability and got better results.\n",
    "\n",
    "Another problem i encountered was that the perplexity of the laplace model was very high, so I tried to solve this problem by changing the way I calculated the perplexity, but I didn't get a better result. I tried to understand why this was happening, but I couldn't find the answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
